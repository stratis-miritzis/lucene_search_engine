## Αναφορά **προαιρετικού τμήματος**

Για το προαιρετικό κομμάτι της εργασίας πρέπει να φτιάξουμε ένα μοντέλο παραγωγής διανυσματικών αναπαραστάσεων (embedding) το οποίο θα χρησιμοποιηθεί από το την μηχανή αναζήτησης για σημασιολογική αναζήτηση.

Στην εργασία μας φτιάξαμε 3 μοντέλα, 2 word2vec(skipgram,cbow) και ένα pretrained μοντέλο της google. Τα word2vec έχουν εκπαιδευτεί από το κείμενο του κάθε review (content).

Για την διευκόλυνση μας η υλοποίηση των embeddings έγινε στην γλώσσα python στο αρχείο embedding_server.py. Κατα την εκτέλεση του αρχείο δίνεται η δυνατότητα επιλογής:
#### 1: Google pretrained word2vec model
#### 2: CBOW embedding model
#### 3: SkipGram embedding model


Χρησιμοποιήσαμε τους 3 αλγορίθμους σε διάφορες λέξεις που περιγράφουν μουσική και καταλήξαμε στο ότι τα word2vec μοντέλα έδιναν τις καλύτερες προτάσεις για την δικιά μας χρήση καθώς ήταν εκπαιδευμένα σε δεδομένα σχετικά με την μουσική, ενώ το μοντέλο της google έδινε πολύ πιο γενικές προτάσεις.
 
 ### Google
![image](https://github.com/stratis-miritzis/anaktisi/assets/21036454/902b2514-aa72-4691-bc18-5e44e899dc23)
  Στην παραπάνω εικόνα φαίνονται οι 10 λέξεις πιο κοντά στην λέξη metal χρησιμοποιώντας το μοντέλο της Google.
Υπο άλλες συνθήκες οι λέξεις aluminium και steel θα ήταν πολύ χρήσιμες για την περιγραφή της λέξης metal, αλλά στο δικό μας εννοιολογικό πλαίσιο δεν βοηθάνε στο να τείνουν την αναζήτηση προς το "metal" που αναζητάει ο χρήστης. 
 
 
 ### CBOW
![image](https://github.com/stratis-miritzis/anaktisi/assets/21036454/ed4ec467-a24e-4cb3-9ce3-c77bd40bba9f)
  Στην παραπάνω εικόνα φαίνονται οι 10 λέξεις πιο κοντά στην λέξη metal χρησιμοποιώντας το μοντέλο CBOW.
Εδώ μπορούμε να παρατηρήσουμε ότι οι προτάσεις thrash, doom, hardcore,sabbath είναι ακριβώς αυτά που θα ήθελε να δει ο χρήστης όταν αναζητάει την λέξη "metal" στο πλαίσιο της μουσικής Google.
  
 ### SkipGram
![image](https://github.com/stratis-miritzis/anaktisi/assets/21036454/9072608e-88f4-417f-b90d-9386121fbe1e)
  Στην παραπάνω εικόνα φαίνονται οι 10 λέξεις πιο κοντά στην λέξη metal χρησιμοποιώντας το μοντέλο Skipgram (thrash,sludge,darkthone). Ενώ οι προτάσεις είναι καλύτερες από αυτές του pretrained μοντέλου της google, είναι πολύ πιο ειδικές από αυτές του CBOW. Αυτό συμβαίνει επειδή σε αντίθεση με το CBOW, το skipgram προσπαθεί να προβλέψει τις υπόλοιπες λέξεις που θα υπήρχαν μαζί με την λέξη αναζήτησης σε μια πρόταση, οπότε τα αποτελέσματα είναι πολύ πιο ειδικά.

 
  Στις εικόνες φαίνεται ότι η κάθε λέξη έχει δίπλα της και έναν αριθμό. Αυτός ο αριθμός είναι το cosine similarity της λέξης αυτής με την λέξη που δόθηκε για αναζήτηση και κυμαίνεται από το 0-1 καθώς είναι κατανομή πιθανότητας. Αυτός ο αριθμός έχει χρησιμοποιηθεί ως συντελεστής βαρύτητας για την κάθε λέξη.


Για την χρήση και την εκπαίδευση των μοντέλων χρησιμοποιήθηκε η βιβλιοθήκη gensim. Μετά την εκπαίδευση ή το κατέβασμα των embeddings χρησιμοποιούμε την βιβλιοθήκη flask για να δημιουργήσουμε έναν api ο οποίος θα δουλεύει στο localhost και στην θύρα 5000. Το api το χρησιμοποιούμε για να στέλνουμε από την java την λέξη που θέλουμε να αναζητήσουμε στην python και μετά αυτή να επιστρέφει τις πιο κοινές λέξεις με αυτές που στείλαμε. Η επιστροφή έχει την δομή:
#### OR thrash^0.751 doom^0.724 hardcore^0.721 grindcore^0.705 sabbath^0.702 sludge^0.68
Χρησιμοποιούμε τις ιδιότητες του query της lucene https://lucene.apache.org/core/2_9_4/queryparsersyntax.html#Fuzzy%20Searches.
Με το OR δίνουμε στο query την δυνατότητα να ψάξει για την λέξη κλειδί ή τις παραγόμενες λέξεις από το embedding. Δίπλα σε κάθε λέξη υπάρχει το σύμβολο ^ που υποδεικνύει ότι η λέξη αυτή θα δεχτεί ένα **boosting**. Ο αριθμός boosting είναι ένας θετικός αριθμός ο οποίος χρησιμοποιείται για να δώσουμε βαρύτητα σε κάποια λέξη, δηλαδή οι αριθμοί με μεγαλύτερο boosting θα έχουν προτεραιότητα στο scoring των αποτελεσμάτων του query. Το default boost factor είναι 1. Χρησιμοποιώντας την κατανομή πιθανότητας ως boost factor είμαστε εγγυημένοι ότι το boost factor θα είναι αριθμός κινητής υποδιαστολής από το 0 εως το 1. Αυτό είναι επιθυμητό καθώς θέλουμε η αναζήτηση να γίνεται κυρίως με τις λέξεις κλειδιά (το κείμενο αναζήτησης) και μετά με τις παραγόμενες λέξεις από το embedding.

![image](https://github.com/stratis-miritzis/anaktisi/assets/21036454/8281eff5-ae62-42ed-ac25-691c1319ac34)

Στην παραπάνω εικόνα κάνουμε σημασιολογική αναζήτηση επειδή έχουμε κάνει check το κουτί _Semantic Search_, και ψάχνουμε την λέξη metallica στο field artist. Παρατηρούμε ότι η σημασιολογική αναζήτηση δουλεύει καθώς έχουμε ως αποτελέσματα καλλιτέχνες παρόμοιους με τους metallica.
